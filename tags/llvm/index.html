<!DOCTYPE html>
<html lang="ja">

<head><title>
    LLVM | 
    
    SE Can&#39;t Code</title>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description" content="This is a Software Engineer, not System Engineer.
    ">


<meta property="og:title" content="LLVM" />
<meta property="og:description" content="This is a Software Engineer, not System Engineer." />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://sott0n.github.io/tags/llvm/" />
<meta property="og:updated_time" content="2019-04-19T07:50:26+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="LLVM"/>
<meta name="twitter:description" content="This is a Software Engineer, not System Engineer."/>

<meta itemprop="name" content="LLVM">
<meta itemprop="description" content="This is a Software Engineer, not System Engineer.">

<link rel="canonical" href="https://sott0n.github.io/tags/llvm/" />

<link rel="icon" type="image/png" href="https://sott0n.github.io/image/favicon.ico">

<link rel="stylesheet" href="/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/bulma.min.css">





<script src=/js/ramium.js></script>
<link rel="stylesheet" href=/css/ramium.css>





</head>

<body><nav class="navbar is-dark" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href=/>
      
      <strong>SE Can&#39;t Code </strong>
      
    </a>

    <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false"
      data-target="navbarBasicExample">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

  <div id="navbarBasicExample" class="navbar-menu">
    <div class="navbar-start">
      
      
      <a class="navbar-item" href="/">Home</a>
      
      
      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">This Blog</a>
        <div class="navbar-dropdown">
          
          <a class="navbar-item" href="/tags/">All Tags</a>
          
          <a class="navbar-item" href="/sections/">All Sections</a>
          
          <a class="navbar-item" href="/posts/">All Posts</a>
          
        </div>
      </div>
      
      
      
      <a class="navbar-item" href="/authorr/">Author</a>
      
      
    </div>

    <div class="navbar-end">
      

      
      <div class="navbar-item">
        <form id="cse-search-box-form-id" onsubmit="return executeQuery();" role="search">
          <div class="field has-addons">
            <div class="control is-expanded">
              <input id="cse-search-input-box-id" size=15 class="input" type="text" autocomplete="off"
                placeholder="&#xf1a0; Google search" style="font-family:Arial, FontAwesome">
            </div>

            <div class="control">
              <button type="submit" class="button is-black">
                <i class="fa fa-search"></i>
                </a>
              </button>
            </div>
          </div>
        </form>
      </div>
      
    </div>
  </div>
</nav><div class="columns is-centered">
        <div id="page-body" class="column is-7">

<div class="content">
    <h1>LLVM</h1>
</div>

<div class="blog-brief">
    <a href="/post/mlir/">
        <h3 class="title is-4">
            MLIR: 新しいTFコンパイラインフラとなる中間表現について
        </h3>
    </a>

    <div class="level is-mobile details">
        <div class="level-left">

            
            <div class="level-item">
                <a href="/post/mlir/">
                    <p class="subtitle info date">Apr 19, 2019
                    </p>
                </a>
            </div>
            


            <div class="level-item">
                <a href="/post/mlir/">
                    <p class="subtitle info">
                        11 mins read
                    </p>
                </a>
            </div>
        </div>
        <div class="level-right is-hidden-touch">
            
            <a class="tag is-rounded" href="/tags/llvm">LLVM</a>
            
            <a class="tag is-rounded" href="/tags/ml">Ml</a>
            
        </div>
    </div>

    <div>
        

        <div>
            <a href="/post/mlir/">
                <p class="summary">
                    2019 European LLVM Developers Meetingを眺めていたらGoogleがMulti-Level Intermediate Representation for Compiler Infrastructureと言う 新しい中間表現の発表をしていたので気になって調べてみた。どうも複雑怪奇になっているTensorFlowのコンパイラエコシステムを一つにまとめる新しいインフラとしての中間表現っぽい。 いくつかの関連する資料を読んだのでそれぞれポイントを抜粋しようと思う。
tl;dr MLIR(Multi-Level Intermediate Representation)を一言で表すと:
 TensorFlowの新しいSSAベースの中間表現 複雑化しているTensorFlowのコンパイラ郡を統一する目的がある LLVMのデザインに強く影響を受けており、柔軟なインフラ設計となっている  位置付けとしては、一つ上位レイヤを追加して共通フォーマット的なメタ表現を設計したというイメージ。 これによって各アーキテクチャ毎に独自のIRを生成する必要がなくなって、開発者にとってはMLIRを意識すれば柔軟に開発が行えるというものだと思う。
複雑化したTFコンパイラ TensorFlowにはいくつかのコンパイラが存在する。それぞれCPU/GPU/TPU、モバイルといったターゲットとなるアーキテクチャ毎にコンパイラ(XLA/TensorRT/nGraph/CoreML/TensorFlow Lite etc)が存在し、 これらは開発が進むと共に複雑化していった。
たとえば、TensorFlow XLAの場合だと HLOと言う中間表現に変換してグラフ最適化などを実行した上で、LLVM IRに変換してCPUやGPU向けにコードジェネレーションを行ったり、 TPU IRに変換してTPU用に最適化をかけたりする。Tensor RTはNVIDIAが出しているコンパイラだが、NVIDIAのGPUアーキテクチャをターゲットにする場合はこれを利用するとNVIDIA特化の最適化が行われる。 モバイル上でDeep Learningを動かしたい場合はTensorFlow Liteを利用するだろう。
このような複雑怪奇な状態は開発者をとても困惑させる。と言うのも、それぞれのコンパイラではそれぞれの中間表現を設計しており、それらはとても似ているが決して同じものではないので、 複数のアーキテクチャをターゲットにした場合は一つ一つ最適化を掛け直し、path変換を行わなければならない。また、それぞれでエラーメッセージの設計も違うので、開発者をとても困惑させるだろう。
MLIRとは MLIRはこれらの問題を解決する新しい中間表現として設計されている。最新の最適化コンパイラのための柔軟なインフラで、また、LLVMのデザインに強く影響を受けている。 たとえば以下のようなところはLLVMと似たデザインとなっている:
 SSAベースな中間表現 柔軟な型システム tree address 構造が同じ(Module/Function/Block/Instruction) 同じ単位の中で複数レベルの抽象化を組み合わせたグラフの表現/分析/変換が可能  また、これらの抽象概念には、TensorFlow操作、入れ子になった多面体ループ領域、さらにはLLVM命令、さらには固定ハードウェア操作とタイプが含まれる。
先にも書いたがTensorFlowにはいくつかのコンパイラとそれに紐づく中間表現があり、 これらは演算子のセマンティクスが異なるため、言語の各層ごとに構築する表現が異なっている。 MLIRはそれらの中間表現に対するメタ表現的な位置付けで、共通フォーマット化をしようとするインフラとしての方針を指している。
MLIR Dialects MLIRは下記をターゲットとしてサポートしている:
 TensorFlow IR, which represents all things possible in TensorFlow graphs XLA HLO IR, which is designed to take advantage of XLA’s compilation abilities (with output to, among other things, TPUs) An experimental affine dialect, which focuses on polyhedral representations and optimizations LLVM IR, which has a 1:1 mapping between it and LLVM’s own representation, allowing MLIR to emit GPU and CPU code through LLVM TensorFlow Lite, which will translate to running code on mobile platforms  Dialectsはカスタム型を定義することができる。 これにより将来的にどのDialectsであれ、LLVM IR型システム(ファーストクラスの集合体を持つ)、量子化型のようなML最適化アクセラレータにとって重要なドメイン抽象化、そしてSwiftまたはClang型システムが得られる。
                    
                </p>
            </a>
        </div>
    </div>

    <div class="level is-mobile continue-reading">
        <div class="level-left">
        </div>
        <div class="level-right">
            <a href="/post/mlir/">Continue reading <i class="fa fa-angle-double-right"
                    aria-hidden="true"></i></a>
        </div>
    </div>
    <hr>
</div>





















        </div>
    </div>
<script async src="https://cse.google.com/cse.js?cx=google-search-code"></script>
<gcse:searchresults-only></gcse:searchresults-only>


<footer class="footer has-background-dark">
    <div class="content has-text-centered has-text-white">
        <p>
            © 2020 Ramium. Powered by
            <a class="has-text-light" href="https://github.com/gohugoio/hugo" target="_blank">
            Hugo</a>. Theme
            <a class="has-text-light" href="https://github.com/rafed123/ramium/" target="_blank">
                Ramium.
            </a>
        </p>
    </div>
</footer>
</body>

</html>